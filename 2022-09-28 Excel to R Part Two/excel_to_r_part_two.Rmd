---
title: 'Excel to R: Part Two'
author: "Adnan Shroufi"
date: "2022-09-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, echo = FALSE)
options(scipen = 999)
```

# Introduction -----------------------------------------------------------------

## Introduction to Excel -> R: Part One

This is a follow-up to the first Excel to R C&C session.
That session focused mostly on using the {dplyr} and {tidyr} packages, for data processing tasks like those you'd do in Excel.
As mentioned in the first session, while Excel is the appropriate tool for some tasks, it does have some limitations, which include:

- Excel can be slow when working with large files
- Going over the same steps in Excel every day/week/month to generate the same report/analysis is time consuming and repetitive.

Using R can can overcome these issues for the following reasons:

- R can work with large files far more easily and quickly
- A single R script can do all of the time consuming and repetitive tasks for you

## Session Format

This session will look at a real example of an excel workflow that has been turned into an R script.
The uses various time and date fields in order to generate some 

## Load Packages

Before we load in our data, we need to make sure have all the required packages installed.
A 'package' is basically a collection of functions. You need to install a package first before you can use it.
We can use `install.package("package_name")` to install a package.
We then use `library(package_name)` to load the package.

There are 2 packages we'll be using quite a lot.
Those are {dplyr} and {lubridate}, for data processing and working with dates.
The other six packages will be used infrequently.

```{r, echo=FALSE}
# Frequently used libraries 
library(dplyr)
library(lubridate)

# Infrequently used libraries 
library(openxlsx)
library(bizdays)
library(readr)
library(scales)
library(jsonlite)
library(janitor)
library(stringr)
```

## Working with dates in R

Many typical reporting tasks in Excel use date fields.
Numerical or character formatted columns can be converted to a date format in R.
Once in a date format, we can then easily do all sorts of date-related calculations.

First we will load in some dummy dates with some unformatted dates.
We will also use the str() function to check the 'structure' of this data, i.e. what data types the columns are.
Each columns is a character (chr).

```{r, echo=FALSE}
# Load in dummy dates data
dummy_dates = read.csv("dummy_dates.csv")

# Check structure of the initial data
str(dummy_dates)
```

## Format each date field accordingly

We can change a character to a date using as.Date() within a mutate().
mutate() either creates a new column or overwrites an existing column.
The only difficulty here is specifying the format.
The format depends on how the character has been spelt.

We have to tell R whether to look for a '/', '-', or '.' between the date elements.
We then have to tell it what position the year (Y), month (m) and (d) come.

```{r, echo=FALSE}
dummy_dates = dummy_dates %>% 
  mutate(date_one = as.Date(date_one, format = "%d/%m/%Y")) %>% 
  mutate(date_two = as.Date(date_two, format = "%d.%m.%Y")) %>% 
  mutate(date_three = as.Date(date_three, format = "%Y-%d-%m")) %>% 
  mutate(date_four = as.Date(date_four, format = "%d/%m/%Y"))

# Re-check structure of the now processed data
str(dummy_dates)
```

## Some very simple examples of date field calculations

Once in a date format, various calculations can be easily done.
Here are just a small selection.

```{r, echo=FALSE}
dummy_dates %>% 
  mutate(
    diff = date_one - date_two,
    day = lubridate::day(date_one),
    month = lubridate::month(date_one),
    year = lubridate::year(date_one),
    first_day_month = lubridate::floor_date(date_one, unit = "month"),
    first_day_year = lubridate::floor_date(date_one, unit = "year")
  ) %>% 
  select(-c(date_three, date_four))
```

## Further Information on {lubridate}

An entire C&C could easily be devoted to just dates and datetime in R.
If you need an analysis in terms of hours and minutes rather than just days, you would need 'datetime' rather than 'date' fields.
The {lubridate} package can deal with both dates and datetimes.
The below {lubridate} cheat sheet demonstrates many of these. 

```{r, echo=FALSE}
browseURL("https://rawgit.com/rstudio/cheatsheets/main/lubridate.pdf")
```

# Case Study: GHIC Dispatch Waiting Times --------------------------------------

## Background

This analysis measures the rate dispatched Health Insurance Cards within a given. 
Once an applicant has successfully applied for a GHIC, a card is ISSUED. 
Cards are then bundled together several times a day and SUBMITTED to an external company to print. 
That company then sends a file back to us to confirm the date it was DISPATCHED.
The process could be summarised as: APPLIED -> ISSUED -> SUBMITTED -> DISPATCHED

There is a KPI present for the SLA target on the number of working days elapsed between ISSUED and DISPATCHED.
10 days or less is within SLA, more that 10 days is out of SLA.

## Loading the data

We will be working with various fields that we want in a date format, in order to do date calculations.
Rather than just load in our CSV file, we check how different CSV-loading functions load the data in.
Loading data is using the most appropriate package can simplify a workflow.

Base-R loads all of the date-related fields as a character.

```{r, echo=FALSE}
# check structure of data if loaded with base-R
print(str(read.csv("Wait_Times_GHIC_MAR_2022_ZIP.csv")))
```

The {readr} package very conveniently parses some fields as date and some as datetime.

```{r, echo=FALSE}
# Check structure of data if loaded with 'readr'
str(readr::read_csv("Wait_Times_GHIC_MAR_2022_ZIP.csv"))
```

Loading the data with {readr} gets us closer to what we want, so we will use this to load the data.
We can then use head() to inspect the first several rows.
We will also use the lubridate::day() function to generate todays date, which we need later on.

```{r, echo=FALSE}
# Define file path so don't need to repeat it
data = readr::read_csv("Wait_Times_GHIC_MAR_2022_ZIP.csv")

# Have a look at some rows of the data 
head(data)

# Create report date
report_date <- as.Date(lubridate::today())
```

## Initial Basic Processing

First we use janitor::clean_names() to simplify the column names.
We will then name the 'submitted' ccolumn name for ease of refernce too.

```{r, echo=FALSE}
# Process data
data_edit = data %>% 
  # Clean names
  janitor::clean_names() %>% 
  # Rename one variable
  rename(submitted_date = submitted_to_xerox)
```

## Change all Datetime Columns to Date data-type

Conveniently, moving from datetime to date is very easy in R.
We do not even need to specify the format, like we did in the introduction.
We can then check the format of the enw ouptut.

```{r, echo=FALSE}
data_edit = data %>% 
  # Clean names
  janitor::clean_names() %>% 
  # Rename one variable
  rename(submitted_date = submitted_to_xerox) %>% 
  # change all posixct to date format
  mutate(application_date = as.Date(application_date)) %>% 
  mutate(issued_date = as.Date(issued_date)) %>% 
  mutate(expired_date = as.Date(expired_date)) %>% 
  mutate(rejected_date = as.Date(rejected_date)) 

# Check data
str(data_edit)
```

## Creating New Columns with Case-Statements

We now need to do some calculations with the data.
Below is a quick explanation as to how case statements work in R.
The order of a case-statement is *very* important.
This decides which values cannot be 'overwritten' by following conditions.

```{r}
# Create 2 similar case statements with different outputs
data.frame(value = c(4,8,12,16,20)) %>% 
  mutate(
    case_one = case_when(
      value <= 20 ~ "Less than 20",
      value <= 10 ~ "Less than 10"
    )
  ) %>% 
  mutate(
    case_two = case_when(
      value <= 10 ~ "Less than 10",
      value <= 20 ~ "Less than 20"
    )
  )
```

## Create a Start Date Column

We want to generate a start_date column, using a case-statement, now knowing how they operate.
Depending on th record, this is either the rejected_date, reissue_request_date or issued_date (in that order).
If none of these values are present we will generate a dummy date instead.

```{r, echo=FALSE}
# Process data
data_edit = data %>% 
  # Clean names
  janitor::clean_names() %>% 
  # Rename one variable
  rename(submitted_date = submitted_to_xerox) %>% 
  # change all posixct to date format
  mutate(application_date = as.Date(application_date)) %>% 
  mutate(issued_date = as.Date(issued_date)) %>% 
  mutate(expired_date = as.Date(expired_date)) %>% 
  mutate(rejected_date = as.Date(rejected_date)) %>% 
  # Create a 'start date' field 
  mutate(
    start_date = case_when(
      !is.na(rejected_date) ~ rejected_date,
      !is.na(reissue_request_date) ~ reissue_request_date,
      !is.na(issued_date) ~ issued_date,
      T ~ as.Date("3099-12-31")
    )
  )

# Check output and related columns
head(data_edit %>% select(rejected_date, reissue_request_date, issued_date, start_date))
```

## Create an End-Date Column

We now want to generate an end_date column.
Depending on the record, this is either the rejected_date or the dispatched_date.
If none of thse values are present we will use todays date (report_date) instead, suggesting the process is ongoing.

```{r, echo=FALSE}
# Process data
data_edit = data %>% 
  # Clean names
  janitor::clean_names() %>% 
  # Rename one variable
  rename(submitted_date = submitted_to_xerox) %>% 
  # change all posixct to date format
  mutate(application_date = as.Date(application_date)) %>% 
  mutate(issued_date = as.Date(issued_date)) %>% 
  mutate(expired_date = as.Date(expired_date)) %>% 
  mutate(rejected_date = as.Date(rejected_date)) %>% 
  # Create a 'start date' field 
  mutate(
    start_date = case_when(
      !is.na(rejected_date) ~ rejected_date,
      !is.na(reissue_request_date) ~ reissue_request_date,
      !is.na(issued_date) ~ issued_date,
      T ~ as.Date("3099-12-31")
    )
  ) %>% 
  # Create a 'end date' field
  mutate(
    end_date = case_when(
      !is.na(rejected_date) ~ rejected_date,
      !is.na(dispatched_date) ~ dispatched_date,
      T ~ report_date
    )
  )

# Check output and related columns
head(data_edit %>% select(rejected_date, dispatched_date, end_date))
```

## Creating a Status Column

Finally for this section, we will create a status field, this field is generated from multiple conditions. Those conditions are:

- If the default start_date is present, then classify the status as 'MISSING START DATE'
- If the rejected_date is present, then classify the status as 'REJECTED'
- If the dispatched_date is present, then classify the status as 'DISPATCHED'
- If the submitted_date is present, then classify the status as 'SUBMITTED'
- If the issued_date is present, then classify the status as 'ISSUED'
- If the rerequest_date is present, then classify the status as 'REREQUEST'
- If none of the above dates are present, then classify the status as 'ERROR'

Remember, the case-statement 'prioritises' earlier conditions over later ones. 


```{r, echo=FALSE}
# Process data
data_edit = data %>% 
  # Clean names
  janitor::clean_names() %>% 
  # Rename one variable
  rename(submitted_date = submitted_to_xerox) %>% 
  # change all posixct to date format
  mutate(application_date = as.Date(application_date)) %>% 
  mutate(issued_date = as.Date(issued_date)) %>% 
  mutate(expired_date = as.Date(expired_date)) %>% 
  mutate(rejected_date = as.Date(rejected_date)) %>% 
  # Create a 'start date' field 
  mutate(
    start_date = case_when(
      !is.na(rejected_date) ~ rejected_date,
      !is.na(reissue_request_date) ~ reissue_request_date,
      !is.na(issued_date) ~ issued_date,
      T ~ as.Date("3099-12-31")
    )
  ) %>% 
  # Create a 'end date' field
  mutate(
    end_date = case_when(
      !is.na(rejected_date) ~ rejected_date,
      !is.na(dispatched_date) ~ dispatched_date,
      T ~ report_date
    )
  ) %>% 
  # Create a 'status' field
  mutate(
    status = case_when(
      start_date == "3099-12-31" ~ "MISSING START DATE",
      !is.na(rejected_date) ~ "REJECTED",
      !is.na(dispatched_date) ~ "DISPATCHED",
      !is.na(submitted_date) ~ "SUBMITTED",
      !is.na(issued_date) ~ "ISSUED",
      !is.na(reissue_request_date) ~ "REREQUEST",
      T ~ "ERROR"
    )
  ) %>% 
  # Create a 'dispatch month' field
  mutate(dispatch_month = floor_date(dispatched_date, unit = "month"))

# Check output and related columns 
head(data_edit %>% select(start_date, rejected_date, dispatched_date, submitted_date, issued_date, reissue_request_date, status, dispatch_month))
```

## Using the Coalesce function

In this instance we can use coalesce() to find the most non-missing (NA) date across multiple fields in our data.
We can also stipulate a value is all the columns we are looking at are missing.
coalesce() is simple, concise and useful in many reporting situations. 

```{r}
data.frame(
  a = c(NA, NA, NA, NA, 5),
  b = c(NA, NA, 90, 8, 9),
  c = c(NA, 100, 67, 0, NA)
  ) %>% 
  mutate(
    coalesce_one = coalesce(a, b, c),
    coalesce_two = coalesce(c, b, a),
    coalesce_three = coalesce(a, b, c, 999)
  )
```

## Replace 2 Case-Statements with Coalesce to Simplify Code

We will now replace the first 2 case-statements with a simple coalesce function. 
This simplifies the code a fair amount.

```{r}
# Newly edited data
data_coalesce = data %>% 
  # Clean names
  janitor::clean_names() %>% 
  # Rename one variable
  rename(submitted_date = submitted_to_xerox) %>% 
  # change all posixct to date format
  mutate(application_date = as.Date(application_date)) %>% 
  mutate(issued_date = as.Date(issued_date)) %>% 
  mutate(expired_date = as.Date(expired_date)) %>% 
  mutate(rejected_date = as.Date(rejected_date)) %>% 
  # Create a 'start date' and 'end date' field 
  # The two new coalesce functions
  mutate(start_date = coalesce(rejected_date, reissue_request_date, issued_date, as.Date("3099-12-31"))) %>% 
  mutate(end_date = coalesce(rejected_date, dispatched_date, report_date)) %>% 
  # Create a 'status' field
  mutate(
    status = case_when(
      start_date == "3099-12-31" ~ "MISSING START DATE",
      !is.na(rejected_date) ~ "REJECTED",
      !is.na(dispatched_date) ~ "DISPATCHED",
      !is.na(submitted_date) ~ "SUBMITTED",
      !is.na(issued_date) ~ "ISSUED",
      !is.na(reissue_request_date) ~ "REREQUEST",
      T ~ "ERROR"
    )
  ) %>% 
  # Create a 'dispatch month' field
  mutate(dispatch_month = floor_date(dispatched_date, unit = "month"))
```

## Compare Dataframes to Make Sure the Code is Running as Intened

As we created a new dataframe above, we can now compare the 'coalesce output' with the previous output.
setdiff() tells you which records across 2 dataframes differ.
If the number of columns or rows differ across 2 dataframes then the function will naturally tell you this and not bother to compare records.
This is a useful to check if 2 objects are identical.

```{r}
# check if outputs are the same
setdiff(data_edit, data_coalesce)
```

# Working Days Calculations ----------------------------------------------------

# Get a List of Holiday Dates

We now want to calculate the number of working days between ISSUE and DISPATCH, to see if we are within or out of the 10 working day SLA time period.
However, we need to take account of bank holidays in addition to weekends.
So we need a list of bank holidays in the first instance.
We can get them from the GOV.uk website in json format.
Here is what the json format data looks like. 

```{r}
browseURL("https://www.gov.uk/bank-holidays.json")
```

We can download this json data using the jsonlite package and then extract the bits we are intereted in, namely the England bank holiday dates.
We use the '$' symbol to access different levels of the json, which has 'nested' lists within lists.
After extracting the dates we want we can turn them into a single column dataframe and change the data into a date format.

```{r}
# Retrieve and format json data
dates = jsonlite::read_json("https://www.gov.uk/bank-holidays.json")

# convert date info to dataframe with a single column
holiday_dates = dates$`england-and-wales`$events %>% 
  bind_rows() %>% 
  select(date) %>% 
  rename(Date = date) %>% 
  as.data.frame() %>% 
  mutate(Date = as.Date(Date))

# Check data type of dates
str(holiday_dates)
```

## Use {bizdays} to Calculate the Difference in Working Days

We can use the {bizdays} package to calculate working day differences.
First we need to calculate a 'calendar' object.

```{r}
#Working with bizdays to calculate time
my_calendar = bizdays::create.calendar(
  name = "WorkCal",
  holidays = holiday_dates$Date,
  weekdays = c("saturday", "sunday"),
  start.date = as.Date("2020-01-01"),
  end.date = as.Date("2023-12-31")
  )

# check holidays within the calendar
my_calendar$holidays
```

We can use the bizdays() within {bizdays} to calculate the working day difference.
If this difference is 10 days or less, we are within the SLA.
If the difference is more than 10 days, we are outside the SLA.

```{r}
# Final data
data_edit = data_edit %>% 
  mutate(sla_days = bizdays::bizdays(start_date, end_date, my_calendar)) %>% 
  mutate(in_sla = ifelse(sla_days <= 10, "Yes", "No")) %>% 
  filter(status == "DISPATCHED")

# Inspect new columns
head(data_edit %>% select(status, sla_days, in_sla))
```


# Remove object and clean
rm(data, data_coalesce)
gc()

# Format final data
output = data_edit %>% 
  mutate(type = "GHIC") %>% 
  group_by(type, dispatch_month, in_sla) %>% 
  summarise(count_by_sla = n()) %>% 
  ungroup() %>% 
  mutate(total = sum(count_by_sla)) %>% 
  mutate(percent = scales::percent(count_by_sla / total, accuracy = 0.00001)) %>% 
  rename_all(.funs = stringr::str_to_title) %>% 
  mutate(Dispatch_month = paste0(
    lubridate::month(Dispatch_month, label = T), " - ", lubridate::year(Dispatch_month)
  ))

# Inspect final data
output

# Check directory
getwd()

# Format output
excel_sheets = list(
  output,
  holiday_dates
)

# Save simple output
openxlsx::write.xlsx(excel_sheets, file = "SIMPLE_OUTPUT.xlsx")

# Create formatted output
wb = createWorkbook()

# Define sheet names
addWorksheet(wb, "March Output")
addWorksheet(wb, "Holiday Dates")

# Modify base font for cells
modifyBaseFont(wb, fontSize = 10, fontName = "Arial")

# Create manual header style
header_style <- createStyle(
  textDecoration = "BOLD", 
  fontColour = "white", 
  fgFill = "#4F81BD",
  border = c("top", "bottom", "left", "right")
)

# Write data to sheets and apply style and specify borders
writeData(wb, "March Output", output, headerStyle = header_style, borders = "columns")
writeData(wb, "Holiday Dates", holiday_dates, headerStyle = header_style, borders = "columns")

# Define column widths
setColWidths(wb, sheet = 1, cols = 1:6, widths = c(10, 18, 10, 15, 10, 10))
setColWidths(wb, sheet = 2, cols = 1, widths = 10)

# Save formatted data
saveWorkbook(wb, "FORMATTED_OUTPUT.xlsx", overwrite = T)

#-------------------------------------------------------------------------------

# Funtions used

# - lubridate::today()
# - lubridate::month()
# - lubridate::year()
# - lubridate::floor_date()

# - dplyr::select()
# - dplyr::mutate()
# - dplyr::case_when()
# - dplyr::filter()
# - dplyr::group_by()
# - dplyr::summmarise()
# - dplyr::ungroup()
# - dplyr::coalesce()
# - dplyr::rename()
# - dplyr::rename_all()
# - dplyr::bind_rows()

# - openxlsx::write.xlsx()
# - openxlsx::createWorkbook()
# - openxlsx::addWorksheet()
# - openxlsx::modifyBaseFont()
# - openxlsx::createStyle()
# - openxlsx::writeData()
# - openxlsx::setColWidths()
# - openxlsx::saveWorkbook()

# - stringr::stringr_to_title()

# - jsonlite::read_json()

# - scales::percent()

# - readr::read_csv()

# - janitor::clean_names()

# - bizdays::bizdays()
# - bizdays::create.calendar()

# - str()
# - setdiff()
# - rm()
# - gc()
# - table()
# - sum()
# - paste0()
# - ifelse()
# - as.Date()
# - list()
# - getwd()

#-------------------------------------------------------------------------------
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
