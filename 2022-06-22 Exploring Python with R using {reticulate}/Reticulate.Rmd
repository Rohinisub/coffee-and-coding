---
title: "Binary classification with R and Python"
author: "Kayoung Goffe"
date: "04/05/2022"
output: pdf_document
---

```{r setup, include=FALSE}
library(reticulate)
library(mlbench)
library(magrittr)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)

```

## Reticulate

The {reticulate} package integrates Python with R. 
Today we will run a simple machine learning for the binary classification. Binary classification is one of supervised learning method. 


## Python configuration 

We need to create conda environment and install few packages. `conda_list()` function returns an R `data.frame`, with  
name giving the name of the associated environment, and Python giving the path to the Python binary associated with that environment.

```{r check conda list}

conda_list()

```
Why do we create our own conda environment? 

Sometimes you want to have very specific version of Python or related libraries for your project. From my limited experience working on MSc Machine Learning project, I encountered the breaking changes error. For example, Python version was not compatible with tensorflow library.

The environment consists of a certain Python version and relevant packages. It is particularly useful if you want to share your code with other colleagues. (similar reason why some people prefer to use `renv`). Further reading can be found [here:](https://towardsdatascience.com/why-you-should-use-a-virtual-environment-for-every-python-project-c17dab3b0fd0)


So, let's create our own conda environment using `conda_create(cc_env)` 


```{r create my own conda environment}

# define our environment name
cc_env <- "coffee_coding_reticulate"

# create conda environment
conda_create(cc_env)

# check the conda environment
conda_list()
# We can see that new environment has been created.
```
Now we added new environment. Let's install python packages in our coffee and coding environment. 

```{r install python libraries to new environment}

# indicate that we want to use the environment we have just created
use_condaenv("coffee_coding_reticulate")

# install few most commonly used python packages; pandas, numpy, seaborn (for visualisation), scikit-learn (popular machine learning library) 
conda_install("coffee_coding_reticulate", "pandas")
conda_install("coffee_coding_reticulate", "numpy")
conda_install("coffee_coding_reticulate", "seaborn")
conda_install("coffee_coding_reticulate", "matplotlib")
conda_install("coffee_coding_reticulate", "scikit-learn")


```
You can use `py_install()` function as well if you prefer. It will require to install miniconda in your system. We are not using it today as we don't want to install while using binder.

So far we have 1) created our own environment called 'coffee_coding_reticulate' and in that environment, we have installed four Python packages. Let's import these newly installed Python libraries in our R environment.

If you have anaconda installed, you will be able to see the new environment in Anaconda too. You can install Python libraries through Anaconda if you want. I will show you on my local machine as I have installed Anaconda. 

Next, let's read our data using R way.

```{r read diabetes data from mlbench}

data(PimaIndiansDiabetes2)
head(PimaIndiansDiabetes2)

# Remove NA values and save as diabetes object
diabetes <- na.omit(PimaIndiansDiabetes2)

# splitting data into features and predicted variable
# We will standardise the predictor variables 
x <- scale(diabetes[,1:8])
# make sure it has binary( 0 = neg, 1=pos) variable
y <- ifelse(diabetes[,9]=='neg',0,1)

# combine to create data frame and split them for 
diabetes_scaled <- data.frame(x,y)

x <- diabetes_scaled %>% 
  select(-y)
y <- diabetes_scaled %>% 
  select(y)

```

Quick note on each variable:
* Pregnant: Number of times pregnant
* Glucose: Plasma glucose concentration (glucose tolerance test)
* Pressure: Diastolic blood pressure (mm Hg)
* Triceps: Skinfold thickness (mm)
* Insulin: 2-Hr serum insulin (mu U/ml)
* Mass: Body mass index (weight in Kg/ (height in m)Â² )
* Pedigree: Diabetes pedigree function
* Age: Age (years)

### Casting R object to Python using {r_to_py()}

You can try various ways of using R & Python together! We will **pass R to Python object** using **`{r_to_py()}`**. In this way, we can use Python libraries.


```{r import Python libraries}

# Python essential numpy, pandas are imported
numpy <- import("numpy")
pandas <- import("pandas")
sns <- import("seaborn")
plt <- import("matplotlib.pyplot")

# scikit-learn libraries
# They look different from ususal python way.. 
skl_preprocessing <- import("sklearn.preprocessing")
skl_model_selection <- import("sklearn.model_selection")
skl_linear_model <- import("sklearn.linear_model")
skl_metrics <- import("sklearn.metrics")

```

We now import Python libraries in R. To use these libraries, let's cast R object to Python.

```{r cast R to Python}

py_diabetes <- r_to_py(diabetes_scaled)

# check first few rows and try pandas function to see whether it returns correct information.
py_diabetes$head()
py_diabetes$dtypes
py_diabetes$describe() # R summary(diabetes)
# check the length of pandas data frame
py_len(py_diabetes)

```
We can see that we can easily cast R object to Python. We are going to run binary classification using `scikit-learn` library. We will do following steps:
* Cast x (independent) and y (dependent) to Python object
* Split train and test dataset
* Run logistic regression


```{r split training and test dataset}


test_train <- skl_model_selection$train_test_split(x,y,test_size = 0.2)

py_x_train <- r_to_py(test_train[[1]])
py_x_test <- r_to_py(test_train[[2]])
py_y_train <- r_to_py(test_train[[3]])
py_y_test <- r_to_py(test_train[[4]])

py_x_train$head() # it is python pandas object now

```
```{r model}
logit_model <- skl_linear_model$LogisticRegression()
logit_model$fit(py_x_train, py_y_train$values$ravel())
logit_prediction <- logit_model$predict(py_x_test)

# generating accuracy score
logit_score <- skl_metrics$accuracy_score(py_y_test, logit_prediction)

logit_report <- skl_metrics$classification_report(py_y_test, logit_prediction,output_dict=TRUE)

logit_report # need to figure out to create better one 

df <- pandas$DataFrame(logit_report)

# python table not show nicely so transpose 
df |> tibble::rownames_to_column() |> 
  tidyr::pivot_longer(
    !rowname, names_to = "col1", values_to = "col2") |> 
  tidyr::pivot_wider(
    names_from = "rowname", values_from = "col2"
  )
  



```
plot using python package 

```{r}

```

using python in chunk
```{python }
import numpy as np

```









 

