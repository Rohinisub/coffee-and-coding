{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fb1ef3-0e84-4cd2-9e19-3e4dc581881d",
   "metadata": {},
   "source": [
    "# Using Python For the First Time (Part II): Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbb38c-b15f-4048-ae4e-40ecf94fea2d",
   "metadata": {},
   "source": [
    "Data cleaning is the process of preparing data for analysis by identifying and fixing problems with the data. This can include things like \n",
    "- removing missing or duplicate values, \n",
    "- correcting inaccuracies, and \n",
    "- formatting data in a consistent way. \n",
    "\n",
    "Data cleaning is important because if the data is not cleaned, the results of any analysis or decision making using that data may be inaccurate or unreliable. It is a necessary and critical step in the data analysis process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c4198-92da-4729-80f9-d87e73f9335f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Packages and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84b866-0b16-4b13-828f-2ce18a2a7f19",
   "metadata": {},
   "source": [
    "First we need to load our packages.. Or in this case package. As discussed in the previous Python for the first time session, Pandas is a powerful Python library used for data manipulation and analysis. Therefore, it is capable of acomplishing all of the data cleaning steps and analysis by itself.\n",
    "\n",
    "If pandas is not already installed, we can install it by navigating back to the launcher by clicking the blue '+' in the top left, just above your files.\n",
    "Then, open a 'terminal' and type `pip install pandas`. Please see the first session notebook for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd22be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042e5104-99a0-48ab-86ce-d303b19db103",
   "metadata": {},
   "source": [
    "Next, we import our dataset. Remember from the last session, we can do this using the Pandas function `pd.read_csv(...)`, entering our file path between the brackets and assigning the results to the variable `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_raw.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc889b-6db0-4e4c-92ec-11839bf3b9b0",
   "metadata": {},
   "source": [
    "For this exercise, we are using some example survey data from Kaggle, collecting information around mental health in tech roles. Please see https://www.kaggle.com/datasets/osmi/mental-health-in-tech-2016 for more information. For the purposes of this exercise, some additional fields have been added.\n",
    "\n",
    "printing the dataset by typing `data`, we notice a few issues with the data immediately, including:\n",
    "\n",
    "- There are spaces and special characters such as a question mark in the column names. These are not allowed in column names because they can cause issues with syntax and make the column name harder to reference. Typically, the special characters are removed and spaces are replaced with a different character, such as an underscore, in order to be used in queries or code.\n",
    "\n",
    "- The `Survey Date` field appears to be in the wrong date format. In Python, dates are wrote in the format: `YYYY-MM-DD` to standardise from the different conventions between countries such as the UK and US versions (`DD/MM/YYYY` vs `MM/DD/YYYY`).\n",
    "\n",
    "- There seems to be errors in certain columns, such as line 2 for the `How many employees does your company or organization have?`, where there is a date instead of an amount of employees specified. Furthermore, for the `What is your gender?` column, there is multiple distinct entries for males, including `\"male\", \"Male\" and \"MALE\"`.\n",
    "\n",
    "- Finally, there are some NULL values, represented in Python by either `None` or `NaN` such as line 0 for the `If yes, what condition(s) have you been diagnosed with?` column.\n",
    "\n",
    "Addressing each issue in order, we start with renaming the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad3749-b9e5-47bb-a044-7d66469bacba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rename Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132eb12-28bc-49dd-8e0c-136f5c558834",
   "metadata": {},
   "source": [
    "To access the columns names of the dataset, we simply use the following, remembering that we manipulate datasets by supplying the name, followed by a `.` and then a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1699a52-f226-4be8-baef-247de0859e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f66c6a-42bf-41ee-863c-ab5e1eff2e2c",
   "metadata": {},
   "source": [
    "To change the column names, we simply need to create a list of our new names, wrapping them in square brackets and then assigning this to the dataset names like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['survey_date', \n",
    "           'age', \n",
    "           'gender', \n",
    "           'self_employed',\n",
    "           'number_of_employees',\n",
    "           'years_employed',\n",
    "           'has_mental_health', \n",
    "           'conditions']\n",
    "\n",
    "data.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b097ce3-18bb-4d30-8035-ead7e044ea05",
   "metadata": {},
   "source": [
    "Alternatively, the list of names can be supplied to the `pd.read_csv(...)` command via `names = columns`. Doing this, we must also supply `header = 0` to make sure it doesn't include our original headers from the first row of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5370db-11be-4d31-801c-7fb88baea2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_raw.csv', names = columns, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0c937-bad0-4ca2-82e4-0989658f5c8b",
   "metadata": {},
   "source": [
    "Printing the first two rows of the dataset, we can see that the names have been changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd672e-2cf2-4a4b-932c-f182b683d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9ff50-940d-4da3-9dc9-494e1bd806df",
   "metadata": {},
   "source": [
    "## Convert Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652f904-60f7-4b0f-92a3-81f32785cfa0",
   "metadata": {},
   "source": [
    "**For the last point, a good first check on any dataset is to check the associated type of each column to make sure it is as expected. We can do this by running `data.dtypes` below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c66d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d804a-fbc9-47e6-b323-2b8261cdb2d4",
   "metadata": {},
   "source": [
    "Within Pandas data frames, there are different types of data that can be used. These types include:\n",
    "\n",
    "- Datatime (`datetime`): This data type is used to hold date and time.\n",
    "- Integer (`int`): this is a whole number, like `1`, `2`, or `-5`.\n",
    "- Numeric (`float`): this is a number with a decimal point, like `3.14` or `-0.01`.\n",
    "- Boolean (`bool`): this is a type that can have only two values: `True` or `False`.\n",
    "- Character or String (`object` or `str`): this is a type that holds words or sentences, like `\"Hello World\"` or `\"dog\"`. Strings can be enclosed in single or double quotes and can include letters, numbers, and symbols.\n",
    "\n",
    "Each column in a DataFrame can have a different data type, and pandas automatically assigns a data type to a column when the data is loaded into the DataFrame. However, you can also explicitly specify the data type of a column when creating a DataFrame or convert the data type of a column later on.\n",
    "\n",
    "Each type of data has its own specific use and rules. For example, you can't apply maths with a word but you can with a number.\n",
    "It is important to use the right type of data in the right place so that the program can understand it and use it correctly.\n",
    "\n",
    "Finally, each data frame has an index which can be either an integer or a label, and it is used to identify and reference the rows of the DataFrame. In the above data, you can see the index on the far left, starting from 0 and ending at 1432. \n",
    "\n",
    "\n",
    "Additionally, there exists many formats for storing data including:\n",
    "\n",
    "- Data Frames (`pd.DataFrame`): this is exclusively controled by the Pandas package is an formatted nXn matrix containing all of our rows and columns.\n",
    "- Series or List (`pd.Series` or `list`): this is a type that holds a group of items, like a list of numbers `[1,2,3]`. You can also imagine this as a single column of a dataframe.\n",
    "- Dictionary (`dict`): this is a type that holds a group of items, like a list, but each item has a name called key. An example would be `{\"Key1\": Value1, \"Key2\": Value2}`.\n",
    "- Tuple (`tuple`): this is a type similar to a list, but the items cannot be changed once created.\n",
    "- Set (`set`): this is a type that holds a group of unique items, like a set of numbers `{1,2,3}`.\n",
    "\n",
    "\n",
    "Each type of data has its own specific use and rules. For example, you can't do math with a word but you can do math with a number.\n",
    "It is important to use the right type of data in the right place so that the program can understand it and use it correctly.\n",
    "\n",
    "From the above we can see that the `survey_date` and `age` columns are incorrectly classified as an `object`, where they should be `datetime` and `int` respectively. Additionally, `self_employed` could be converted to `bool`, where 1 = True and 0 = False.\n",
    "\n",
    "To convert `survey_date` into `datetime`, we use the pandas function `pd.to_datetime(...)`, supplying the date column (remeber we access specific columns via square brackets) and the format. Note here that the format is what the data currently is, not what it is being converted into. A full list of formats can be found here: https://www.w3schools.com/python/python_datetime.asp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a5b95c-2e22-4dbc-9be3-28b38caa67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_date'] =  pd.to_datetime(data['survey_date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0311140e-967a-4b1f-adb8-8b5c63e177a5",
   "metadata": {},
   "source": [
    "To convert `self_employed` into `bool`, we simply apply `.astype('bool')` to the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da75e9b-2d93-469c-8eb6-1c7f2d1f4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['self_employed'] = data['self_employed'].astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace9c000-41b8-4908-ad0b-64d4fe7f5b2a",
   "metadata": {},
   "source": [
    "Finally, attempting the cast `age` to the `int` type using the same method, we receieve an error that the field contains words, which are not allowed under the integer type. Therefore, we must first remove these values before we can convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b88be-f18e-4a2a-bb5a-482587e66fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['age'] = data['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20640e19-0fa2-4d64-8a17-d5bd9346c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c307b7c4-2005-4a99-a010-8292286ffc0b",
   "metadata": {},
   "source": [
    "## Detect Outliers with Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841b11f-b3b3-440c-8741-19a1f9c97c79",
   "metadata": {},
   "source": [
    "In Python, a function is a block of code that can be reused multiple times. Functions help to organize and structure code, making it easier to read and understand. Functions are defined using the \"def\" keyword, followed by the name of the function, and a set of parentheses `()` that can include input parameters. The code that makes up the function **MUST** be indented, using the TAB button on your keyboard and placed underneath the definition.\n",
    "\n",
    "For example, the following code defines a function called \"greet\" that takes in a name as a parameter and prints out a greeting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4af3b9-f5b1-443d-a252-e5632e5fe3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name):\n",
    "   print('Hello, ' + name + '!')\n",
    "\n",
    "greet('John')\n",
    "greet('Jane')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc1314-a894-4c86-8b6d-d54e8f16fc17",
   "metadata": {},
   "source": [
    "In this example, the function \"greet\" is defined on the first line, and it is called twice on the last two lines, with the input parameters \"John\" and \"Jane\" respectively.\n",
    "Functions can also return a value using the return statement, which allows you to use the result of the function in other parts of your code. \n",
    "\n",
    "Here's an example of a function that takes in two numbers and returns the sum of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f07d21-913d-41be-9d57-483a7b2b280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "  x = a + b\n",
    "  return x\n",
    "\n",
    "result = add(3, 4)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04698b-e61d-4953-9c0e-5e47e979aaa3",
   "metadata": {},
   "source": [
    "In this example, the function add takes in two numbers a and b and return their sum. The return statement allows the function to output the sum, which is then stored in the variable result and printed out.\n",
    "\n",
    "In this instance, for our data, we want to take a count of each distinct value in a column and sort the count in descending order. We do so below, applying `.value_counts()` and `.sort_values(ascending = False)` to the column `survey_date`. Remember here, you can specify a `\\` to tell Python that code is going on a new line for neatness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_date'].value_counts() \\\n",
    "                   .sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c2fad-1757-4be8-b999-0cf000415d9e",
   "metadata": {},
   "source": [
    "Here we can see that two future dates have been used: `2025-06-01` and `2023-05-01` which haven't occured yet and must be wrong. We will deal with these in the next section.\n",
    "\n",
    "To generalise this code into a function called `my_counter`, we specifiy `column` as the input and replace `'survey_date'` above with the input `column`. Finally, we assign the output to result and add `return result` so that the function returns an output. Without this line, the function would do nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce576c5e-d363-4a2e-88f1-ac22910e6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_counter(column):\n",
    "    result = data[column].value_counts() \\\n",
    "                         .sort_values(ascending = False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1207d4-cd03-4d1b-b9d4-a6c1984df7f6",
   "metadata": {},
   "source": [
    "Running the function with `'survey_date'`, we receieve the same output as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f6fff-e00b-4b68-868a-5538d83299ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('survey_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f363c4c-4d89-4a8f-a1ab-cf2feb82c940",
   "metadata": {},
   "source": [
    "Finally, we can redo the function to add some extra functionality. Namely, we supply `dropna = False` within .values_counts() to also count NULL values and we add `normalize = prop` to optionally turn the counts into proportions, where `prop` is an additional input supplied. Notice here that we have done `prop = False` which tells Python that by default prop is equal to `False`. Doing this means that we don't need to supply prop each time, just if we want to change `prop` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48311bfa-bd7e-4f25-8798-386d1a09d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_counter(column, prop = False):\n",
    "    result = data[column].value_counts(normalize = prop, dropna = False) \\\n",
    "                         .sort_values(ascending = False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0523adb-4952-4119-b63c-2dee4d688fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('survey_date', prop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a1f74a-18e1-4617-97d3-855bdd1f5eaa",
   "metadata": {},
   "source": [
    "## Fixing Data Errors with Conditional Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7f9e1-2c1c-49c7-952d-15ce9fb64821",
   "metadata": {},
   "source": [
    "To fix data errors, we either eplace the error in question with:\n",
    "\n",
    "- a NULL value, indicating that it is \"non-applicable\" or\n",
    "- an appropriate value. \n",
    "\n",
    "In the latter case, there a few options including the mean/median/mode of the column, the previous value and others. It's important to know your data before applying any of these, as any of these methods can lead to lose of information.\n",
    "\n",
    "Typically, we would go through each column of the data individually, inspecting it in order to indentify any errors and deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b7824-ee36-4c9e-8a9e-e787b40fab93",
   "metadata": {},
   "source": [
    "### Survey Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75dba7a-3878-42d7-8212-4cf0879ec745",
   "metadata": {},
   "source": [
    "Returning to the `survey_date` column from the previous section, we already identified that two future dates have been used: `2025-06-01` and `2023-05-01` which haven't occured yet and must be there by mistake. We can filter our data like so to indentify the full rows where these errors occur. Remember from the previous session, we apply this to `data` by wrapping our filters in square brackets. If there is more than one filter, each filter must also be wrapping in circle brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['survey_date'] == '2025-06-01') | (data['survey_date'] == '2023-05-01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13daff6-3b2a-4819-9ef8-545edf1848c5",
   "metadata": {},
   "source": [
    "Given that the dataset is a survey, we suspect that each row was enetered cronologically as a new response come through. Therefore, we inspect the previous rows of each error, by specifying a list of index numbers to test our theory. Since we are filtering by a list of values, these must be wrapped in additional square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['survey_date'][[30, 36, 44, 52, 87, 139]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb8202-5485-41e1-9d0d-406e352ca908",
   "metadata": {},
   "source": [
    "As suspected, it looks like all of these responses should have occured on the 1st Jan 2022. Therefore, we use if/else logic where if the `survey_date` column is equal to either of the two erronous dates, then they should be replaced with '2022-01-01'. To do this, we use`.loc` at the front of the dataset to indicate that we are wanting to replace values. Then we must supply the column that we want to change at the end after our filters. Finally, we assign a new value at the end.\n",
    "\n",
    "**Remember here that `==` is where something is equal to something else. `=` is used to assign a result to variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['survey_date'] == '2025-06-01') | (data['survey_date'] == '2023-05-01'), 'survey_date'] = '2022-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7391cc6-9161-48df-a483-3a2170158fcf",
   "metadata": {},
   "source": [
    "We can check this worked by filtering where the index of the data was equal to 31, which we know was one of the rows with an error from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac14e22-9759-40f6-8a64-20e50c9cfe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.index == 31]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5684675-815e-4be0-ab97-2a1450be9c91",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a951772-33e2-4aa4-b56c-39eaf6c7128b",
   "metadata": {},
   "source": [
    "Applying our `my_counter()` to `age`, we identify three errors: `'thirty six'`, `'forty three'` and `'twenty nine'` where the ages have been wrote as text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ef697-625d-453d-9294-d443cafc37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab3a4dc-4f78-457f-8e9b-5c87eb05e1c5",
   "metadata": {},
   "source": [
    "We can again filter the dataset to see the full rows. This time we can can use the `.isin()` function, specifying a list of values rather than three individual filters for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0e52-d105-40b3-9091-1b1f09827a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['age'].isin(['thirty six', 'forty three', 'twenty nine'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ad84c-2a8b-419f-a029-c99f2fb229d1",
   "metadata": {},
   "source": [
    "To use our logic from the `survey_date` example, we would have to supply three seperate filters and replacements here with the below:\n",
    "\n",
    "```\n",
    "data.loc[data['age'] == 'thirty six', 'age'] = '36'\n",
    "data.loc[data['age'] == 'forty three', 'age'] = '43'\n",
    "data.loc[data['age'] == 'twenty nine', 'age'] = '29'\n",
    "```\n",
    "\n",
    "Alternatively, we can create a dictionary here. Remember from above that a dictionary is simply a list of values with names, wrote in the format: `{'key1': value1, 'key2': value2}`. Here, the `key:value` pairs here are the current values and replacements. We then use `.replace({column: our_dictionary})` to replace the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a994ee-619c-4c43-ae0f-057c5a569959",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = {\n",
    "  'thirty six': 36,\n",
    "  'forty three': 43, \n",
    "  'twenty nine': 29\n",
    "}\n",
    "\n",
    "data = data.replace({'age': numbers})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eaf6a7-7e1d-4d26-b071-597d3265d330",
   "metadata": {},
   "source": [
    "Remembering our inability to cast the `age` column to an integer from before, we can now do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca852d4-4bee-4d36-8048-cbb90ad1dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = data['age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d13da0d-b92d-4840-859d-691953f9962c",
   "metadata": {},
   "source": [
    "Now that `age` is an integer, we can check for outliers within the column by filtering the data where the age is less than equal to 18 or greater than equal to 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503e722-3382-4459-a468-cfe7a547b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['age'] <= 18) | (data['age'] >= 80)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44282bc-bc24-4a3c-8a8c-af0457466228",
   "metadata": {},
   "source": [
    "Here, one could imagine that a 17 year old could realistically work for a tech company while the others are unlikely. Therefore we use `.loc` to replace the values below 15 and greater or equal to 80 with the mean of the `age` column. Notice we add `.astype(int)` to round the mean to a whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d4504-643e-4c98-b3df-7cba3a0047b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['age'] <= 16) | (data['age'] >= 80), 'age'] = data['age'].mean().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa8df7-2e08-4480-b054-f53f6c9651c0",
   "metadata": {},
   "source": [
    "We can again check this worked by supplying the index of one of the outlier rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466a899-6dd5-4411-8e64-19f1d7628752",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.index == 631]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd778936-f7f7-4a14-89a5-3a744b9b73d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aca298-06f9-4412-a79d-b3a1a014c9e7",
   "metadata": {},
   "source": [
    "Look at the values for `gender`, there are a lot of distinct values that exist for male, female and other genders. Typically, we would look to indentify trends in the names to alter all of them into a single format. Here however, there is a lot of distinct response with no real pattern. Therefore, it is easiest to create two lists, one for all of the male values and one for the female values. Then we just have to use `.replace(list, replacement_value)` to replace each value with either `'male'` or `'female'`. For all of the remaining responses, we can then use `.value_counts()` to count and sort for each value, then filter the top two results which will be `'male'` and `'female'` from our previous replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6e249-26b3-49ac-831e-08769e818258",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e216b-f1ce-45a4-92b2-91ab7044367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "male = ['Male', 'male', 'M', 'm', 'Cis Male', 'man', 'ostensibly male, unsure what that really means', 'Mail', 'Make', 'male (cis)', \n",
    "        'cis male', 'maile', 'Malr', 'Cis Man', 'Mal', 'msle', 'male.', 'sex is male', 'malr', 'cis man', 'mail' ]\n",
    "     \n",
    "female = ['Female', 'female', 'F', 'f', 'Woman', 'Femake', 'Female (cis)', 'cis female', 'woman', 'femail', \n",
    "     'cis-female/femme', 'i identify as female.', 'cis-woman', 'cisgender female', 'female (props for making this a freeform field, though)', \n",
    "     'female/woman', 'female assigned at birth' ]\n",
    "\n",
    "data['gender'] = data['gender'].replace(male, 'male')\n",
    "data['gender'] = data['gender'].replace(female, 'female')\n",
    "\n",
    "other = list(data['gender'].value_counts().index)[2:]\n",
    "data['gender'] = data['gender'].replace(other, 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8df65-ae5f-46b5-8512-695868696edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278cc979-ec54-4575-80f0-6bdefcc0605e",
   "metadata": {},
   "source": [
    "### Self Employed Flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea77d0-f445-4773-89bf-3ee34d1f862d",
   "metadata": {},
   "source": [
    "Applying the counter for `self_employed`, there doesn't appear to be any errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833c696c-add5-4d2b-a545-724c5e33c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('self_employed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7ade7-f0ae-4df9-9a1a-c1647fc3992b",
   "metadata": {},
   "source": [
    "Additionally, we apply the counter to `self_employed` and `number_of_employees` together in a list, to make sure nobody who is self employed has a value for number of employees. Thankfully, that is true here. However, from the `number_of_employees` column, we can see there are two incorrect values `'2025-06-01 00:00:00'` and `'2023-05-01 00:00:00'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b7da4-8e52-444f-bfe1-74029dedb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter(['self_employed', 'number_of_employees'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85193641-efe7-47b3-a674-2a3bb7c62802",
   "metadata": {},
   "source": [
    "### Number of Employees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21438b96-21b9-42eb-9a8c-cb51dea367dd",
   "metadata": {},
   "source": [
    "Again, we provide a list of \"correct\" values and replace where if the value is not in the list, we assign a NULL value of `None`. Note here, the terminology for \"not in\" is supplying a `~` just after the opening square bracket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c597d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['26-100', '100-500', '500-1000', 'More than 1000']\n",
    "data.loc[~(data['number_of_employees'].isin(categories)), 'number_of_employees'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e5fe0-9b65-4c05-9f5d-60f812b5270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('number_of_employees')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dadad38-2e11-49a2-9707-7dc755c5f29c",
   "metadata": {},
   "source": [
    "### Years Employed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16922be5-6847-4c77-8993-5a4d050a4deb",
   "metadata": {},
   "source": [
    "The `years_employed` field is strangly a float type, containing decimals and numbers. Therefore we can use `data.describe()` to see statistics about the field such as the min, max, mean and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff932e-b162-482c-a97b-a1d9b27478e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1b419-9932-4f00-96dd-19285c6237ad",
   "metadata": {},
   "source": [
    "Again all looks good here, though this field should probably be an integer. We can convert by first apply `np.floor()` from the numpy package, round every value down and then cast as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a2a6f-bcb0-43f1-9e97-a0c957a0f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['years_employed'] = np.floor(data['years_employed']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8adc72-2b4b-41fd-8bb1-f9e171d46aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35170f03-020b-40a5-87d4-08d2e3b99760",
   "metadata": {},
   "source": [
    "### Has Mental Health Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a673c-0cfb-43ea-aad5-c43a2792a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_counter('has_mental_health')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e2cdc4-6880-4dbf-9112-eac584f3cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['has_mental_health'] == 'Yes') & (data['conditions'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe6264-1494-444c-a8d5-4d2ce3f6c31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa66f7-8eea-4d63-8498-213fd0418696",
   "metadata": {},
   "source": [
    "For the last step, we need to handle the NULL values within the dataset. NULL values exist where there doesn't exist a value for that particular row. There are several techniques for handling missing data, depending on the specific situation and the type of data. Some common techniques include:\n",
    "\n",
    "- Filling the missing value with an appropriate measure such as mean, median, or value from the previous row. This method is useful when the data is missing at random.\n",
    "- Dropping the rows that contain the NULL values. This is only effective if there a small amount of rows to be removed to not lead to loss of information.\n",
    "- Dropping the columns that contains NULLs, often if there are two many to extract any insights from that column.\n",
    "- Keeping the NULLs and filling with a placeholder such as -1 or NA to extract insights from where the values are NULL.\n",
    "\n",
    "It's important to note that there isn't one best method to handle missing data, the best method will depend on the specific dataset and problem, it is recommended to try different methods and compare the results.\n",
    "\n",
    "To identify which rows and columns contain nulls, we use the `.isnull()` function. We can then add a `.sum()` and `.sort_values()` to identify the amount per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac7609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull() \\\n",
    "    .sum() \\\n",
    "    .sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70727807-996a-4811-a4db-74e9090e29c6",
   "metadata": {},
   "source": [
    "Given the `gender` column has only three NULL values, we can simply remove these rows by filtering where the values are not null and assigning that back to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7235f-80b5-4fbd-b644-18a259d6f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['gender'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48f2b0-4296-4469-9a82-bf32f5ce9bfb",
   "metadata": {},
   "source": [
    "On the flip side, `conditions` is made up mostly of NULLs and is therefore relatively useless. We can use `.drop()` to remove the column, specifying `axis = 1` to tell the function to look within the columns. To remove rows, one can use `axis = 0.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf644d44-b66c-4501-a20c-c127629bf8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('conditions', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcea2f-8f67-4d6b-a357-222aa1c92b66",
   "metadata": {},
   "source": [
    "Finally, for the `number_of_employees` column, we know there is a NULL value when the employee is self employed. Therefore, we can fill where this is true with a `'Self Employed'` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98522951-2f41-4a77-b848-a4c9b5c43c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['self_employed'] == True, 'number_of_employees'] = 'Self Employed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d50392-23f2-4e09-bc8c-57b64916ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull() \\\n",
    "    .sum() \\\n",
    "    .sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff2cda4-2fd3-48e2-81b8-006c6a8a4d33",
   "metadata": {},
   "source": [
    "From the above, there still exists NULL values within `number_of_employees` so we fill this with an 'NA' placeholder to plot later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbb9e7-5258-410a-86c2-b430ad26b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['number_of_employees'].isnull(), 'number_of_employees'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bde69-3215-4bde-8dac-748d677125f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull() \\\n",
    "    .sum() \\\n",
    "    .sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7d504-6bfd-4ec9-9019-e37d2e4d5679",
   "metadata": {},
   "source": [
    "## Analysis using Seaborn and Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54ebfb-bce0-42a9-9a90-e7754235d936",
   "metadata": {},
   "source": [
    "In the previous session, we plotted our data using the `matplotlib` package. This time will focus on the `seaborn` package which arguably creates nicer looking visuals compared with the former. We first must load `seaborn` and `matplotlib` which we will use in conjuction with seaborn to view the plots. If these are not installed, one can do `pip install ...` in the terminal as we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71cdc1-7880-4ed2-860c-6bd53613b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34272b96-a7fe-4956-abd4-0c697d66ee1e",
   "metadata": {},
   "source": [
    "First we need to gather some data to plot. As we did above, we use `value_counts()` to count each value combination, convert the result to a dataset with `reset_index()` and rename our count column to `count` using the `.rename()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ffc99-af86-4897-8521-9140038f5963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['gender', 'has_mental_health']].value_counts() \\\n",
    "                                          .rename('count') \\\n",
    "                                          .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd3c93-4a6f-4716-89c0-efd4106f5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9a78d-939f-485f-9a6b-42fcc6b70092",
   "metadata": {},
   "source": [
    "We can also add the proportion per `gender` by dividing each `count` value by the sum of each `gender` value via the `.transform('sum')` command. Note we can use `normalize = True` within `.value_counts()` above as this takes the proportion for all values, not specifically to `gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af7544-ff19-48d7-93f4-2b1f3f40914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['proportion'] = df['count'] / df.groupby('gender')['count'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f438ea-5b95-484f-b8cf-6acffa0d1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fbe2e5-b58e-499f-91ef-9b4ebb2aeeed",
   "metadata": {},
   "source": [
    "We then plot the proportion of `df` with each `gender` on the x axis, and `has_mental_health` as the colour. Notice the code here is relatively similar to the `matplotlib` layout in the previous session. We:\n",
    "- Setup the plot with `plt.figure()` and `plt.figure(figsize=(15, 5))`\n",
    "- Plot via `sns.barplot(...)`. One can choose from many plots here such as sns.lineplot(...), we just choose a barplot in this case.\n",
    "- Then set labels and a title after with `.set_xlabel()`, `.set_ylabel` and `.set_title` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8d1be-7dc6-4989-a078-c833c85e58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plot = sns.barplot(data=df, x='gender', y='proportion', hue='has_mental_health')\n",
    "plot.set_xlabel('Gender')\n",
    "plot.set_ylabel('Proportion')\n",
    "plot.set_title('Proportion of those who have mental health by Gender')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c715d6c-bbcb-4557-b925-a7f76b84ffe5",
   "metadata": {},
   "source": [
    "If we wanted to plot this for the other columns, we could repeat the process: counting per variable, calculating the proportion and plotting again. However a much more elegant way to do this would be to use a \"for loop\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72900b01-499e-427e-8db8-89bdfceb90cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e5415a-c20b-409e-bc1d-c9ec50611675",
   "metadata": {},
   "source": [
    "In Python, loops are used to repeatedly execute a block of code. There are two types of loops: for loops and while loops.\n",
    "- A \"for loop\" is used when you know in advance how many times you want to repeat the actions. For example, if you have a list of 5 items, and you want to print each of them one by one, you would use a for loop. A \"for loop\" iterates over a sequence (such as a list, tuple, or string) and execute the same block of code for each item in the sequence. The basic syntax is:\n",
    "\n",
    "```\n",
    "for variable in sequence:\n",
    "    # code to be executed\n",
    "```\n",
    "\n",
    "- A \"while loop\" is used when you don't know in advance how many times you want to repeat the actions, but you have a certain condition that tells you when to stop. For example, if you want to keep asking a user for their name until they enter it correctly, you would use a while loop. A \"while loop\" is used to repeatedly execute a block of code as long as a certain condition is true. The basic syntax is:\n",
    "\n",
    "```\n",
    "while condition:\n",
    "    # code to be executed\n",
    "```\n",
    "\n",
    "It's important to be careful when using while loops, because if the condition that tells you when to stop is never met, the loop will repeat forever, which is called an infinite loop.\n",
    "\n",
    "In this session we will only be covering \"for loops\". An example would be the following, where for each value between 1 and 5, we want to print each value multipled by 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde131e-5728-4a1c-b11e-e7a29c13d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4, 5]:\n",
    "  print(50 * i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cb72b0-52a3-48ab-b745-49c331edc50d",
   "metadata": {},
   "source": [
    "Given our list of columns, we can use a \"for loop\" to iterate through the columns and plot for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef91d91-824a-4f55-901e-28038a5ef37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c153c828-5383-4b82-8d33-931e78932663",
   "metadata": {},
   "source": [
    "We copy the above code and simply replace `'gender'` with the generic `column` placeholder where each value in `['gender', 'self_employed', 'number_of_employees']` will be inputted in the place of it. For the title on the last line, since our variable will change for each plot, we simply use string manipulating to input the column name within the title to tell the graphs apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5519f-b04c-4239-883f-26aa4f8a83b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['gender', 'self_employed', 'number_of_employees']:\n",
    "  df = data[[column, 'has_mental_health']].value_counts() \\\n",
    "                                 .rename('count') \\\n",
    "                                 .reset_index()\n",
    "  \n",
    "  df['proportion'] = df['count'] / df.groupby(column)['count'].transform('sum')\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  plot = sns.barplot(data = df, x = column, y = 'proportion', hue = 'has_mental_health')\n",
    "  plot.set_xlabel(column)\n",
    "  plot.set_ylabel('Proportion')\n",
    "  plot.set_title('Proportion of those who have mental health by ' + column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502904ad-f70c-43f1-8537-24f874d37873",
   "metadata": {},
   "source": [
    "In addition to the above, you can also use functions in conjuctions with loops. In the below function `my_plotter()` we have copied the code again and replaced 'has_mental_health' with a `legend_col` input in the function to be able to dynamically specify which column determines the colour of the graph. Again for the title, we need to dynamically add this using string manipulation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8205d7f-9ec1-401b-9b5c-045366e17af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plotter(column, legend_col):\n",
    "  df = data[[column, legend_col]].value_counts() \\\n",
    "                                 .rename('count') \\\n",
    "                                 .reset_index()\n",
    "  \n",
    "  df['proportion'] = df['count'] / df.groupby(column)['count'].transform('sum')\n",
    "  \n",
    "  plt.figure()\n",
    "  plt.figure(figsize=(15, 5))\n",
    "  plot = sns.barplot(data = df, x = column, y = 'proportion', hue = legend_col)\n",
    "  plot.set_xlabel(column)\n",
    "  plot.set_ylabel('Proportion')\n",
    "  plot.set_title('Proportion of ' + legend_col + ' by ' + column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c0368-d544-4b9d-a319-cc538339ddbb",
   "metadata": {},
   "source": [
    "Plotting for `gender` and `has_mentaL_health` again using the function returns the previous graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da96d5-6468-492e-b8d4-13bd51d2de7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_plotter('gender', 'has_mental_health')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4df084-2bbc-4901-9785-579434f41bb9",
   "metadata": {},
   "source": [
    "We can now create a \"for loop\" that iterates through `['gender', 'self_employed']`, applying each one as inputs to the function and taking `number_of_employees` as the colour each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0a1f8-463b-480f-a327-b3a5228ef194",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['gender', 'self_employed']:\n",
    "  my_plotter(column, 'number_of_employees')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
