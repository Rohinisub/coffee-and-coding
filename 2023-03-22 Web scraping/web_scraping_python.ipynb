{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a662bc0-abdf-4172-a7f2-4605f65ec508",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Web scraping in Python: Scraping with Requests and BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198cfe14-c38e-40af-86bc-855e4d2ffc72",
   "metadata": {},
   "source": [
    "Web scraping is a valuable tool for programmers to effortlessly gather information from the vast resources of the internet. While it is generally acceptable for non-commercial purposes with publicly available data, caution should be taken to avoid scraping protected information such as personal data, intellectual property, or confidential information. \n",
    "\n",
    "Additionally, the complexities of scraping social media due to its varying levels of accessibility highlight the need for cautious and informed scraping practices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a46aca-f5a1-40e0-96eb-2b8efa2c96bc",
   "metadata": {},
   "source": [
    "This coffee and coding session, we will focus to use Python's two libraries; <b>Requests</b> and <b>BeautifulSoup</b>. <br>http://books.toscrape.com/ contains review  for fake books for the beginners learning web scrapings. <br>\n",
    "This session aims for the beginners (like me!) introduction to web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab24ca1-55a9-49f6-b971-bfa78537b9d4",
   "metadata": {},
   "source": [
    "To gather information from the internet through web scraping, one typically follows a four-step process:\n",
    "\n",
    "<li> Sending an HTTP GET request to the URL </li>\n",
    "<li> Retrieving HTML (Hypertext Markup Language) content </li>\n",
    "<li> Building the HTML document tree </li>\n",
    "<li> Extracting information from the HTML document tree </li>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bf4eb-093a-4405-bd27-dd4766f85acc",
   "metadata": {},
   "source": [
    "### Requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ca3f7d-1090-42e3-a151-98a11e8341f1",
   "metadata": {},
   "source": [
    "The Requests library in Python is a popular and widely used library for making HTTP requests. This library allows user to send HTTP requests to server, receive response and handle in a simple and efficient manner. \n",
    "\n",
    "It supports varous methods for making requests, such as GET, POST, HEAD, PUT, DELETE etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70249c0b-f079-478b-9367-702c130421a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04815663-deda-4065-9faa-a43d15bd369b",
   "metadata": {},
   "source": [
    "BeautifulSoup is a Python library for web scraping and data extraction from HTML and XML files. <br>\n",
    "It provides a convenient and efficient way to parse and naviage through HTML contents, allowing for the extraction of specific elements and data.\n",
    "\n",
    "<b>Resource: https://www.crummy.com/software/BeautifulSoup/bs4/doc/ </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2ceae-1aad-4a89-9091-39b8bd920c3c",
   "metadata": {},
   "source": [
    "We will first fetch HTML code from our fake-books site. But before we start, I will show you a very quick overview of basic HTML. \n",
    "\n",
    "HTML is a standard markup language used for creating web pages and other information that can be displayed in a web browser. It consists of a set of tags and attributes that define the structure, content, and appearance of a web page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59da51-95b8-46bf-a6d1-894bcbfc2e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71072523-70e0-4626-b747-28a9c70f3225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "html_test = \"\"\"\n",
    "<html>\n",
    "  <head>\n",
    "    <title>My First Web Page</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Welcome to my first test web page</h1>\n",
    "    <p>This is a paragraph of text. I want to list some of my favourite composers and their music \n",
    "        <i> Italic font </i>    \n",
    "        <b> Bold text 1</b>\n",
    "        <b> Bold text 2</b>\n",
    "    </p>    \n",
    "    <p> <b color = \"blue\"> This is next paragraph </b></p>\n",
    "    <br>    \n",
    "    <ul id = \"composer\" class = \"myclass\">\n",
    "      <li>Liszt</li>  \n",
    "      <a href = \"https://en.wikipedia.org/wiki/Franz_Liszt\"> Franz Liszt: Hungarian composer, pianist of romantic period. </a>\n",
    "      <li>Mozart</li>\n",
    "      <a href = \"https://en.wikipedia.org/wiki/Wolfgang_Amadeus_Mozart\"> Wolfgang Amadeus Mozart influential composer of classical period. </a>\n",
    "      <li>Debussy</li>\n",
    "      <a href = \"https://en.wikipedia.org/wiki/Claude_Debussy\"> Claude Debussy, French composer seen as the first impressionist. </a>\n",
    "      <li>Beethoven</li>\n",
    "      <a href = \"https://en.wikipedia.org/wiki/Ludwig_van_Beethoven\"> Ludwig van Beethoven, German composer and pianist.</a>\n",
    "    </ul>\n",
    "    <ul id = \"piece\" class = \"myclass\">\n",
    "        <li>Love Dream (No.3)</li>\n",
    "        <li>Piano Sonata No.16</li>\n",
    "        <li>Moonlight</li>\n",
    "        <li>Symphony No.5</li>\n",
    "    </ul>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95168506-313a-4ac1-9e2b-0ce8ec18a146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's import libraries first \n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b0a05f-f129-4a0c-86f7-662f44608426",
   "metadata": {},
   "source": [
    "We explore functions in BeautifulSoup using the sample HTML we've just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24ee1f-bdbb-4a1f-9780-f749affe6426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create soup variable\n",
    "soup = BeautifulSoup(html_test, features = \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68a05a-e3f2-44b7-a94f-a6a5bfe08073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# soup has the information extracted from HTML string. We can make it better display\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c8e9f-9284-4ed6-b1f2-b2fc6d0386ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now indent etc works better\n",
    "# Prettify arranges all the tags in a parse-tree manner with better readability.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d12d4-2977-4f89-89d2-f07a910de42a",
   "metadata": {},
   "source": [
    "When you read HTML, you want to search specific aspect. You can find thins by `tag`. like `<head>`,`<title>` etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8408f-2ce7-4274-9004-7da989c581de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Codes to nativage data structure (https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "display(soup.title) # access title tag\n",
    "display(soup.title.string) # acces title tag and want only access what is inside in the tag\n",
    "# You can also modify string in your tag\n",
    "# soup.title.string = \"My Second web page\"\n",
    "display(soup.p.get_text())\n",
    "display(soup.ul.get_text()) # it returns first ul element only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916076ca-01e3-42b2-a77b-4df6af4b1d9c",
   "metadata": {},
   "source": [
    "Let's try `find()` or `find_all()` functions to search for specific tags in the HTML content. <br>\n",
    "`find()` returns only the first occurrence of the search query. `find_all()` returns a list of all matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eaeac8-6704-452e-8a07-9a94f6cc9a38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(soup.find('a')) # first element of a tag only\n",
    "display(soup.find('a').text) # This allows us to extract the inner HTML text\n",
    "display(soup.find_all('a')) # all a tag elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98dedff-4ffc-4ffd-b2a0-42f988d26874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(soup.find_all(\"p\")[0]) # First element of p tag\n",
    "display(soup.find_all(\"p\")[0].find_all(\"b\")) # inside p tag all b tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd866e-1652-4de2-ad8a-5e834026e27c",
   "metadata": {},
   "source": [
    "If we only want to extract composer items `<li>`, we can use `attr ={}` dictionary to define the attributes of an HTML tag. Dictionary keys are the name of the attributes, and the values are the attribute values.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72379edf-61c2-41f5-9712-a03b689b2032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myList = soup.find(attrs = {'id':'composer', 'class':'myclass'})\n",
    "myList.find_all('li')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975970f-092a-4011-8024-a213a58ef536",
   "metadata": {},
   "source": [
    "You can also traverse the parent and children elements in the HTML code. Below code uses `find_parent()` function to find the parent of the first `ul` tag (`body` tag). It then uses `find_all()` function again to find all the `li` elements in the first `ul` tag and print each `li` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff8914-2a40-4461-a3ed-5365431f81d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First find the first ul tag\n",
    "first_ul = soup.find(\"ul\")\n",
    "\n",
    "# Find the parent of the first ul tag (the body tag)\n",
    "body = first_ul.find_parent(\"body\")\n",
    "\n",
    "# Print the text content of each li element\n",
    "for li in first_ul.find_all([\"a\", \"li\"]):\n",
    "    print(li.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a7627-5f97-4961-836f-a0191e6a6eb5",
   "metadata": {},
   "source": [
    "### Let's try with fake-book review site "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83460a-fb28-41ca-af94-c338cc745b13",
   "metadata": {},
   "source": [
    "We've tried few basics of beautifulsoup functions using our own HTML text. Now, we can go to fake book review sites and extract some information about the books, their prices and book description.\n",
    "Before we start, let's check this webpage and inspect HTML codes. https://books.toscrape.com/catalogue/page-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0467d0de-63b2-4051-aec1-57dc4debe77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import requests and pandas, re as well for regex string manipulation \n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e0f18-5da3-4550-8ad3-50655949fa71",
   "metadata": {},
   "source": [
    "#### Read the first page\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d40ef-d569-4806-934a-b7d015d42967",
   "metadata": {},
   "source": [
    "First, read book title, price and rating. We will then extend this by adding book description. (When user click book title, it takes to the product description page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d9e50-afde-4fc2-9599-eabc81dd2136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# request can get HTML data from the very first page.\n",
    "url = \"https://books.toscrape.com/catalogue/page-1.html\" #page-2 etc will repeat to extract all pages. which we will try in the next section\n",
    "response = requests.get(url) # http request and get the content of the page\n",
    "display(response)\n",
    "# 200 means 'Success' status\n",
    "# If you want to see content of resonse (it will be messy)\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73359e24-c27c-46a8-940d-5c4d00e40ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# You can look at the content using \n",
    "# soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351487b6-7d24-411f-9a94-c6a713dc32d4",
   "metadata": {},
   "source": [
    "Let's go back to our html inspect page extract our interest (book title, price and later description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919328f-bf2a-4790-9dea-f2ed11273e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract first book in the first page to see if this is working.\n",
    "review_mapping = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5} # For mapping for numbers\n",
    "\n",
    "article = soup.find(\"article\")\n",
    "title = article.h3.a[\"title\"]\n",
    "print(title)\n",
    "price = article.find('p', class_=\"price_color\").text \n",
    "price = float(re.findall(\"\\d+\\.\\d+\", price)[0]) #regex + is metacharacters means one or more occurrences\n",
    "print(price)\n",
    "rating = article.p[\"class\"][1] # access secound element one, two, three etc \n",
    "rating = review_mapping[rating]\n",
    "print(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2a22fd8c-6074-4108-bc19-e6ea3555a1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Frankenstein\n",
      "Price: 38.0\n",
      "Rating: 2\n",
      "\n",
      "Title: Forever Rockers (The Rocker #12)\n",
      "Price: 28.8\n",
      "Rating: 3\n",
      "\n",
      "Title: Fighting Fate (Fighting #6)\n",
      "Price: 39.24\n",
      "Rating: 3\n",
      "\n",
      "Title: Emma\n",
      "Price: 32.93\n",
      "Rating: 2\n",
      "\n",
      "Title: Eat, Pray, Love\n",
      "Price: 51.32\n",
      "Rating: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Based on the code above, we can now extract all books in the first page.\n",
    "books = [] # We will append to this list, define empty list\n",
    "\n",
    "for article in soup.find_all(\"article\"):\n",
    "    title = article.h3.a[\"title\"]\n",
    "    # price = article.select_one(\".price_color\").get_text() # another way using select_one (https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors)    \n",
    "    price = article.find('p', class_=\"price_color\").text \n",
    "    price = float(re.findall(\"\\d+\\.\\d+\", price)[0])\n",
    "    rating = article.p[\"class\"][1] # access secound element one, two etc \n",
    "    rating = review_mapping[rating]\n",
    "    books.append({\"title\": title, \"price\": price, \"rating\":rating})\n",
    "      \n",
    "for book in books[0:5]: # First 5 books\n",
    "    print(f\"Title: {book['title']}\")\n",
    "    print(f\"Price: {book['price']}\")\n",
    "    print(f\"Rating: {book['rating']}\")\n",
    "    print(\"\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c9a6944f-8b76-47b1-bbed-01d42fe9e5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Frankenstein\n",
      "Price: 38.0\n",
      "Rating: 2\n",
      "Description: \n",
      "    Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\n",
      "\n",
      "\n",
      "Title: Forever Rockers (The Rocker #12)\n",
      "Price: 28.8\n",
      "Rating: 3\n",
      "Description: \n",
      "    My Happily Ever After was turning into a living nightmare... All I wanted was Harper's happiness and I would move the world to give her anything she ever wanted. We've searched for answers, talked about our options, and finally-FINALLY-found hope. Yet, just when things seemed to be perfect, it all came crashing down around us all. The one person I've always counted on to h My Happily Ever After was turning into a living nightmare... All I wanted was Harper's happiness and I would move the world to give her anything she ever wanted. We've searched for answers, talked about our options, and finally-FINALLY-found hope. Yet, just when things seemed to be perfect, it all came crashing down around us all. The one person I've always counted on to hold us together-to hold me together-was lost in her own nightmares and I felt like I was losing everything. Everything. I wasn't going to lose the woman I loved. I would hold onto her until the last breath left my body. It was my mistakes that were hurting us and I would be the one to fix it. I wouldn't let my past ruin my forever with Harper. ...more\n",
      "\n",
      "\n",
      "Title: Fighting Fate (Fighting #6)\n",
      "Price: 39.24\n",
      "Rating: 3\n",
      "Description: \n",
      "    ***BONUS CONTENT: The first two chapters of JB Salsbury's stand alone novel SPLIT included!Axelleâs broken.I live to hold her together.Killian McCreery only has two dreams . . .Fight for the UFL.And Axelle.Heâs watched her give her time and her body to men who donât deserve to breathe her air. Heâs waited, worked hard to become the kind of man she deserves, hoping one day, ***BONUS CONTENT: The first two chapters of JB Salsbury's stand alone novel SPLIT included!Axelleâs broken.I live to hold her together.Killian McCreery only has two dreams . . .Fight for the UFL.And Axelle.Heâs watched her give her time and her body to men who donât deserve to breathe her air. Heâs waited, worked hard to become the kind of man she deserves, hoping one day, when the time is right, heâd get the opportunity to make her happy. After a painful anniversary, he finally gets his chance.But life has a way of sucker-punching its victimsâstriking when they least expect it in the most devastating ways.Killian loves me.But I screwed up. Big time.Axelle Daniels appears to be the typical college studentâparties, hangovers, and men. No one knows that inside sheâs a mess, and no amount of booze or meaningless relationships have managed to fill the cracks in her heart. But Killian knows. Heâs been there since the night it all began and has never left her side.When she wakes up one morning to find the consequences of her actions have caught up to her, even Killianâs white-knighthood canât save her now.Fate is put to the test when, for the first time in their five-year friendship, they no longer have each other to lean on. When he becomes a UFL superstar, she hardly recognizes the man he used to be. And she no longer needs him to hold her together.With the foundation of their friendship gone, theyâll discover that even a love that is meant to be needs to be fought for and destiny is a choice. ...more\n",
      "\n",
      "\n",
      "Title: Emma\n",
      "Price: 32.93\n",
      "Rating: 2\n",
      "Description: \n",
      "    'I never have been in love; it is not my way, or my nature; and I do not think I ever shall.'Beautiful, clever, rich - and single - Emma Woodhouse is perfectly content with her life and sees no need for either love or marriage. Nothing, however, delights her more than interfering in the romantic lives of others. But when she ignores the warnings of her good friend Mr. Knig 'I never have been in love; it is not my way, or my nature; and I do not think I ever shall.'Beautiful, clever, rich - and single - Emma Woodhouse is perfectly content with her life and sees no need for either love or marriage. Nothing, however, delights her more than interfering in the romantic lives of others. But when she ignores the warnings of her good friend Mr. Knightley and attempts to arrange a suitable match for her protegee Harriet Smith, her carefully laid plans soon unravel and have consequences that she never expected. With its imperfect but charming heroine and its witty and subtle exploration of relationships, Emma is often seen as Jane Austen's most flawless work.This edition includes a new chronology and additional suggestions for further reading. ...more\n",
      "\n",
      "\n",
      "Title: Eat, Pray, Love\n",
      "Price: 51.32\n",
      "Rating: 3\n",
      "Description: \n",
      "    In her early thirties, Elizabeth Gilbert had everything a modern American woman was supposed to want--husband, country home, successful career--but instead of feeling happy and fulfilled, she felt consumed by panic and confusion. This wise and rapturous book is the story of how she left behind all these outward marks of success, and of what she found in their place. Follow In her early thirties, Elizabeth Gilbert had everything a modern American woman was supposed to want--husband, country home, successful career--but instead of feeling happy and fulfilled, she felt consumed by panic and confusion. This wise and rapturous book is the story of how she left behind all these outward marks of success, and of what she found in their place. Following a divorce and a crushing depression, Gilbert set out to examine three different aspects of her nature, set against the backdrop of three different cultures: pleasure in Italy, devotion in India, and on the Indonesian island of Bali, a balance between worldly enjoyment and divine transcendence. ...more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Expand the code from above, include book description\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # request the main page\n",
    "# url = \"https://books.toscrape.com/catalogue/page-1.html\" #page-2 etc will repeat to extract all pages for next step. \n",
    "# response = requests.get(url)\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# # Find all book titles, prices, and customer reviews\n",
    "books = []\n",
    "review_mapping = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5} # For mapping for numbers\n",
    "\n",
    "for article in soup.find_all(\"article\"):\n",
    "    title = article.h3.a[\"title\"]\n",
    "    price = article.find('p', class_=\"price_color\").text \n",
    "    price = float(re.findall(\"\\d+\\.\\d+\", price)[0])\n",
    "    rating = article.p[\"class\"][1] # access secound element one, two etc \n",
    "    rating = review_mapping[rating]\n",
    "    \n",
    "    # find the link to the individual book's page\n",
    "    link = article.h3.a[\"href\"]\n",
    "    split_link = link.split(\"/\")\n",
    "    # link: a-light-in-the-attic_1000/index.html etc \n",
    "    # print(link) \n",
    "    \n",
    "    book_url = \"http://books.toscrape.com/catalogue/\" + link  #get information of individual book link page to take you to the description  \n",
    "    \n",
    "    # request the individual book's page\n",
    "    book_response = requests.get(book_url) #request again to get text of the individual book page.\n",
    "    book_soup = BeautifulSoup(book_response.text, \"html.parser\")\n",
    "    \n",
    "    # extract the product description\n",
    "    # select a meta tag with attribute name = \"description\". The method select_one returns the first matching element, or 'None'\n",
    "    # if there are not matches. ['content'] part is accessing the value of the content attribute of the selected meta tag. \n",
    "    \n",
    "    product_description = book_soup.select_one(\"meta[name='description']\")[\"content\"]  \n",
    "    books.append({\"title\": title, \"price\": price, \"rating\":rating, \"book_description\": product_description})\n",
    "    \n",
    "    \n",
    "\n",
    "for book in books[0:5]: # First 5 books\n",
    "    print(f\"Title: {book['title']}\")\n",
    "    print(f\"Price: {book['price']}\")\n",
    "    print(f\"Rating: {book['rating']}\")\n",
    "    print(f\"Description: {book['book_description']}\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "1b1b1e7d-61cb-41cf-aa13-5696b0b71ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            \n",
      "                Page 1 of 50\n",
      "            \n",
      "            \n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Final stage: Expand further, scraping ALL pages. \n",
    "# However, it takes too long so we will not run this in the session.\n",
    "# I have saved as csv file.\n",
    "# I will explain how I get final page (50) from tag\n",
    "\n",
    "# %%time\n",
    "review_mapping = {\"One\": 1, \"Two\": 2, \"Three\": 3, \"Four\": 4, \"Five\": 5}\n",
    "books = []\n",
    "\n",
    "# # Get the total number of pages\n",
    "url = \"http://books.toscrape.com/catalogue/page-1.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "previous_page = soup.select(\"li.next\")[0].find_previous_sibling(\"li\")\n",
    "if previous_page:\n",
    "    text = previous_page.text # which returns page 1 of 50 and we want to extract 50 from here.\n",
    "    print(text)\n",
    "    # in here extract the last page number \n",
    "    match = re.search(r'Page (\\d+) of (\\d+)', text) # any number\n",
    "    total_pages = int(match.group(2)) # extract last page.\n",
    "    print(total_pages)\n",
    "else:\n",
    "    total_pages = 1\n",
    "\n",
    "\n",
    "# Loop through each page\n",
    "\n",
    "# for page_number in tqdm(range(1, total_pages + 1)):\n",
    "#     url = f\"http://books.toscrape.com/catalogue/page-{page_number}.html\"\n",
    "#     response = requests.get(url)\n",
    "#     soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "#     for article in soup.find_all(\"article\"):\n",
    "#         title = article.h3.a[\"title\"]\n",
    "#         price = article.find(\"p\", class_=\"price_color\").text \n",
    "#         price = float(re.findall(\"\\d+\\.\\d+\", price)[0])\n",
    "#         rating = article.p[\"class\"][1]\n",
    "#         rating = review_mapping[rating]\n",
    "#         link = article.h3.a[\"href\"]\n",
    "#         book_url = \"http://books.toscrape.com/catalogue/\" + link\n",
    "#         book_response = requests.get(book_url)\n",
    "#         book_soup = BeautifulSoup(book_response.text, \"html.parser\")\n",
    "#         product_description = book_soup.select_one(\"meta[name='description']\")[\"content\"]  \n",
    "#         books.append({\"title\": title, \"price\": price, \"product_description\": product_description})\n",
    "        \n",
    "# # Convert the list of dictionaries to a Pandas dataframe\n",
    "# # We will clean the text\n",
    "# df = pd.DataFrame(books)\n",
    "\n",
    "# df.head()\n",
    "# We will use this for the next.\n",
    "# df.to_csv(\"books_web_scraping.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4931ab0f-51b0-4c7c-81ba-5aaf405c6b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
