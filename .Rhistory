conda_install("coffee_coding_reticulate", "numpy")
conda_install("coffee_coding_reticulate", "seaborn")
conda_install("coffee_coding_reticulate", "matplotlib")
conda_install("coffee_coding_reticulate", "scikit-learn")
# Python essential numpy, pandas are imported
numpy <- import("numpy")
pandas <- import("pandas")
import("pandas")
import("numpy")
# install few most commonly used python packages; pandas, numpy, seaborn (for visualisation), scikit-learn (popular machine learning library)
conda_install("coffee_coding_reticulate", "pandas")
# Python essential numpy, pandas are imported
numpy <- import("numpy")
pandas <- import("pandas")
pandas <- import('pandas')
sns <- import("seaborn")
plt <- import("matplotlib.pyplot")
# Python essential numpy, pandas are imported
numpy <- import("numpy")
# scikit-learn libraries
# They look different from ususal python way..
skl_preprocessing <- import("sklearn.preprocessing")
# Python essential numpy, pandas are imported
numpy <- import("numpy")
pandas <- import("pandas")
sns <- import("seaborn")
plt <- import("matplotlib.pyplot")
import("numpy")
import("pandas")
# define our environment name
cc_env <- "coffee_coding_reticulate"
# create conda environment
conda_create(cc_env)
# check the conda environment
conda_list()
# We can see that new environment has been created.
py_config()
conda_list()
library(reticulate)
library(mlbench)
library(magrittr)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
# define our environment name
cc_env <- "coffee_coding_reticulate"
# create conda environment
conda_create(cc_env)
# check the conda environment
conda_list()
# We can see that new environment has been created.
# indicate that we want to use the environment we have just created
use_condaenv("coffee_coding_reticulate")
# install few most commonly used python packages; pandas, numpy, seaborn (for visualisation), scikit-learn (popular machine learning library)
conda_install("coffee_coding_reticulate", "pandas")
conda_install("coffee_coding_reticulate", "numpy")
conda_install("coffee_coding_reticulate", "seaborn")
conda_install("coffee_coding_reticulate", "matplotlib")
conda_install("coffee_coding_reticulate", "scikit-learn")
data(PimaIndiansDiabetes2)
head(PimaIndiansDiabetes2)
# Remove NA values and save as diabetes object
diabetes <- na.omit(PimaIndiansDiabetes2)
# splitting data into features and predicted variable
X <- diabetes[,1:8]
# make sure it has binary( 0 = neg, 1=pos) variable
y <- data.frame(diabetes[,9]) %>%
dplyr::mutate(outcome = ifelse(`diabetes...9.`=='neg',0,1)) %>%
select(outcome)
# Python essential numpy, pandas are imported
numpy <- import("numpy")
pandas <- import("pandas")
sns <- import("seaborn")
plt <- import("matplotlib.pyplot")
# scikit-learn libraries
# They look different from ususal python way..
skl_preprocessing <- import("sklearn.preprocessing")
skl_model_selection <- import("sklearn.model_selection")
skl_linear_model <- import("sklearn.linear_model")
skl_metrics <- import("sklearn.metrics")
py_diabetes <- r_to_py(diabetes)
py_diabetes$head()
diabetes
diabetes %>% heaD()
diabetes %>% head()
py_diabetes$head()
# check first few rows
py_diabetes$head()
py_X <- r_to_py(X)
py_X$head()
py_diabetes$dtypes()
py_diabetes$dtype()
py_diabetes$dtypes
py_diabetes$describe()
summary(diabetes)
py_list_attributes(py_diabetes)
?py_list_attributes()
py_list_attributes(py_X)
# check the length of pandas data frame
py_lengh(py_diabetes)
# check the length of pandas data frame
py_len(py_diabetes)
# check the length of pandas data frame
print(py_len(py_diabetes))
print(py_diabetes$describe()) # R summary(diabetes)
skl_preprocessing$StandardScaler()
py_y = r_to_py(y)
py_X = r_to_py(X)
py_X
py_y
scaler = skl_preprocessing$StandardScaler()
scaler$fit(py_X)
py_X = scaler$fit_transform(py_X)
py_X
# let's quick look whether it did transform the data
py_X$head()
# let's quick look whether it did transform the data
py_X$head
# let's quick look whether it did transform the data
py_X
# let's quick look whether it did transform the data
py_X[10]
# let's quick look whether it did transform the data
py_X[,10]
# let's quick look whether it did transform the data
py_X[1:10]
test_train <- skl_model_selection$train_test_split(py_X,y)
test_train
test_train[[1]]
test_train[[2]]
test_train[[3]]
test_train[[4]]
py_y
y
# make sure it has binary( 0 = neg, 1=pos) variable
y <- data.frame(diabetes[,9]) %>%
dplyr::mutate(outcome = ifelse(`diabetes...9.`=='neg',0,1)) %>%
select(outcome)
py_y = r_to_py(y)
py_X = r_to_py(X)
scaler = skl_preprocessing$StandardScaler()
scaler$fit(py_X)
py_X = scaler$fit_transform(py_X)
# let's quick look whether it did transform the data
# As you can see it now transformed as numpy array
py_X[1:10]
# Transformation is done for independent features
# Now split into training and test
# scikit-learn create tuple which allows multiple assignment but R returns as list and we need to assign them
test_train <- skl_model_selection$train_test_split(py_X,y)
test_train
test_train[[4]]
test_train[[3]]
test_train <- skl_model_selection$train_test_split(py_X,py_y)
tset_train[[4]]
test_train[[4]]
test_train[[1]][1:10]
test_train[[2]][1:10]
test_train[[3]][1:10]
test_train <- skl_model_selection$train_test_split(X,y)
test_train[[3]][1:10]
X
y
test_train <- skl_model_selection$train_test_split(X,y)
data(PimaIndiansDiabetes2)
head(PimaIndiansDiabetes2)
# Remove NA values and save as diabetes object
diabetes <- na.omit(PimaIndiansDiabetes2)
# splitting data into features and predicted variable
X <- diabetes[,1:8]
# make sure it has binary( 0 = neg, 1=pos) variable
y <- data.frame(diabetes[,9]) %>%
dplyr::mutate(outcome = ifelse(`diabetes...9.`=='neg',0,1)) %>%
select(outcome)
py_X = r_to_py(X)
py_X
scaler = skl_preprocessing$StandardScaler()
scaler$fit(py_X)
py_X = scaler$fit_transform(py_X)
py_X
test_train <- skl_model_selection$train_test_split(X,y)
test_train[[3]][1:10]
test_train[[4]][1:10,]
test_train[[3]][1:10,]
test_train <- skl_model_selection$train_test_split(py_X,py_y)
data("BreastCancer")
#convert to numeric for models and remove na values for this example
model_set <- sapply(BreastCancer[complete.cases(BreastCancer),-1], as.numeric)
model_set
#format target variable as 0, 1 instead of 1,2
model_set[,10]<-model_set[,10]-1
#Split into test and train sets
indices <- sample(1:nrow(model_set), size = 0.7 * nrow(model_set))
#Target variables
target<-unlist(model_set[indices,10])
test_target<-unlist(model_set[-indices,10])
target
test_target
#create unscaled data set for boosted tree models
unscale_train<-as.matrix(model_set[indices,-10])
unscale_test<-as.matrix(model_set[-indices,-10 ])
#create normalized data set for neural network
mean <- apply(model_set[indices,-10], 2, mean)
std <- apply(model_set[indices,-10], 2, sd)
train <- scale(model_set[indices,-10], center = mean, scale = std)
test <- scale(model_set[-indices,-10], center = mean, scale = std)
train
test
unscale_train
View(test_train)
py_X_train <- r_to_py(test_train[[2]])
py_X_test <- r_to_py(test_train[[1]])
py_Y_train <- r_to_py(test_train[[4]])
py_Y_test <- r_to_py(test_train[[3]])
py_X_train <- r_to_py(test_train[[1]])
len(py_X_train)
length(py_X_train)
py_X_test <- r_to_py(test_train[[2]])
length(py_X_test)
py_Y_train <- r_to_py(test_train[[3]])
length(py_y_test)
length(py_Y_test)
py_Y_train <- r_to_py(test_train[[3]])
py_Y_test <- r_to_py(test_train[[4]])
logit_model <- skl_linear_model$LogisticRegression
logit_model$fit(py_X_train, py_Y_train)
py_Y_train <- r_to_py(test_train[[3]])
logit_model$fit(py_X_train, py_Y_train)
test_train <- skl_model_selection$train_test_split(X,y)
py_X_train <- r_to_py(test_train[[1]])
py_X_test <- r_to_py(test_train[[2]])
py_Y_train <- r_to_py(test_train[[3]])
py_Y_test <- r_to_py(test_train[[4]])
logit_model <- skl_linear_model$LogisticRegression
logit_model$fit(py_X_train, py_Y_train)
model <- logit_model$fit(py_X_train, py_Y_train)
logit_model <- skl_linear_model$LogisticRegression()
model <- logit_model$fit(py_X_train, py_Y_train)
test_train <- skl_model_selection$train_test_split(py_X,py_y)
py_X_train <- r_to_py(test_train[[1]])
py_X_test <- r_to_py(test_train[[2]])
py_Y_train <- r_to_py(test_train[[3]])
py_Y_test <- r_to_py(test_train[[4]])
logit_model <- skl_linear_model$LogisticRegression()
model <- logit_model$fit(py_X_train, py_Y_train)
diaetes[,9]
diabetes[,9]
type(diabetes[,9])
class(diabetes[,9])
# make sure it has binary( 0 = neg, 1=pos) variable
y <- ifelse(diabetes[,9]=='neg',0,1)
y
py_diabetes <- r_to_py(diabetes)
# check first few rows and try pandas function to see whether it returns correct information.
py_diabetes$head()
py_diabetes$dtypes
py_diabetes$describe() # R summary(diabetes)
# check the length of pandas data frame
py_len(py_diabetes)
py_y = r_to_py(y)
py_X = r_to_py(X)
scaler = skl_preprocessing$StandardScaler()
scaler$fit(py_X)
py_X = scaler$fit_transform(py_X)
# let's quick look whether it did transform the data
# As you can see it now transformed as numpy array
py_X[1:10]
# Transformation is done for independent features
# Now split into training and test
# scikit-learn create tuple which allows multiple assignment but R returns as list and we need to assign them
test_train <- skl_model_selection$train_test_split(py_X,py_y)
py_X_train <- r_to_py(test_train[[1]])
py_X_test <- r_to_py(test_train[[2]])
py_Y_train <- r_to_py(test_train[[3]])
py_Y_test <- r_to_py(test_train[[4]])
logit_model <- skl_linear_model$LogisticRegression()
model <- logit_model$fit(py_X_train, py_Y_train)
model
logit_prediction <- logit_model$predict(py_X_test)
library(reticulate)
library(mlbench)
library(magrittr)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE)
conda_list()
data(PimaIndiansDiabetes2)
head(PimaIndiansDiabetes2)
# Remove NA values and save as diabetes object
diabetes <- na.omit(PimaIndiansDiabetes2)
# splitting data into features and predicted variable
# We will standardise the predictor variables
x <- scale(diabetes[,1:8])
# make sure it has binary( 0 = neg, 1=pos) variable
y <- ifelse(diabetes[,9]=='neg',0,1)
# combine to create data frame and split them for
diabetes_scaled <- data.frame(x,y)
x <- diabetes_scaled %>%
select(-y)
y <- diabetes_scaled %>%
select(y)
# Python essential numpy, pandas are imported
numpy <- import("numpy")
pandas <- import("pandas")
sns <- import("seaborn")
plt <- import("matplotlib.pyplot")
# scikit-learn libraries
# They look different from ususal python way..
skl_preprocessing <- import("sklearn.preprocessing")
skl_model_selection <- import("sklearn.model_selection")
skl_linear_model <- import("sklearn.linear_model")
skl_metrics <- import("sklearn.metrics")
test_train <- skl_model_selection$train_test_split(x,y,test_size = 0.2)
py_x_train <- r_to_py(test_train[[1]])
py_x_test <- r_to_py(test_train[[2]])
py_y_train <- r_to_py(test_train[[3]])
py_y_test <- r_to_py(test_train[[4]])
py_x_train$head() # it is python pandas object now
logit_model <- skl_linear_model$LogisticRegression()
model <- logit_model$fit(py_x_train, py_y_train$values$ravel())
logit_prediction <- logit_model$predict(py_x_test)
# generating accuracy score
logit_score <- skl_metrics$accuracy_score(py_y_test, logit_prediction)
logit_report <- skl_metrics$classification_report(py_y_test, logit_prediction)
logit_report # need to figure out to create better one
logit_score
logit_prediction
reticulate::repl_python()
import numpy as np
exit
print(classification_report(py_y_test, logit_prediction))
print(skl_metrics$classification_report(py_y_test, logit_prediction))
model
logit_model$fit(py_x_train, py_y_train$values$ravel())
logit_model <- skl_linear_model$LogisticRegression()
logit_model$fit(py_x_train, py_y_train$values$ravel())
logit_prediction <- logit_model$predict(py_x_test)
# generating accuracy score
logit_score <- skl_metrics$accuracy_score(py_y_test, logit_prediction)
logit_report <- skl_metrics$classification_report(py_y_test, logit_prediction)
logit_report # need to figure out to create better one
logit_report <- skl_metrics$classification_report(py_y_test, logit_prediction, output_dict=True)
logit_report <- skl_metrics$classification_report(py_y_test, logit_prediction,output_dict=TRUE)
logit_report # need to figure out to create better one
df = pandas$DataFrame(logit_report).transpose()
df = pandas$DataFrame(logit_report)$transpose()
df = pandas$DataFrame(logit_report)$transpose
df
df = pandas$DataFrame(logit_report)$transpose()
pandas$DataFrame(logit_report)
df$transpose
df <- pandas$DataFrame(logit_report)
View(df)
df |> tidyr::rownames_to_column()
df |> rownames_to_column()
?rownames_to_column
df |> tibble::rownames_to_column()
df
df |> tibble::rownames_to_column()
df |> tibble::rownames_to_column() |>
tidyr::pivot_longer(
!rowname, names_to = "col1", values_to = "col2")
df |> tibble::rownames_to_column() |>
tidyr::pivot_longer(
!rowname, names_to = "col1", values_to = "col2") |>
tidyr::pivot_wider(
names_from = "rowname", values_from = "col2"
)
quit
q()
